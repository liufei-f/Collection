{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1925cec5-5b8c-450c-8b86-fc0ee19189f5",
   "metadata": {},
   "source": [
    "\n",
    "# 1. Zero-shot learning(零样本学习)\n",
    "模型能够在没有见过特定任务或样本标签的情况下，对新任务进行预测或分类。\n",
    "它依赖于模型对任务和数据的通用理解，通常通过以下方式实现：\n",
    "1. 利用先验知识：预训练\n",
    "2. 任务描述：通过自然语言描述任务（如文本提示）来指导模型预测，而无需提供特定的训练样本\n",
    "3. 共享特征空间：将未知类别的特征映射到已知类别共享的特征空间，基于语义或上下文进行推断\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71112bcd-9bff-4818-b8d9-0b62830e8387",
   "metadata": {},
   "source": [
    "# 2. Logical Reasoning(逻辑推理)\n",
    "模型根据已知事实/规则或模型进行逻辑分析和推导的能力。\n",
    "1. Deductive reasoning: 从一般规则推导出具体结论\n",
    "2. Inductive reasoning: 从具体例子总结出一般规律\n",
    "3. Abductive reasoning: 从结论推测最可能的原因\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1eb35f7-4cae-42cf-85b4-fd4f39aab32e",
   "metadata": {},
   "source": [
    "\n",
    "# 3. Low-Rank Adaptation(LoRA)\n",
    "是一种高效适配预训练模型的方法，尤其在大规模语言模型或其他深度学习模型上表现出色。它通过引入低秩分解的思想，大幅减少模型参数调整的需求，从而降低计算开销和存储需求。\n",
    "\n",
    "在深度学习中，预训练的大模型通常含有大量的参数，直接对其进行fine-tuning需要巨大的计算资源和存储空间。LoRA通过引入低秩矩阵，将权重调整在一个低秩子空间中，极大的减少了参数调整的数量。\n",
    "1. 权重矩阵分解\n",
    "假设一个预训练模型的权重矩阵为$W$，LoRA假设权重的调$\\Delta W$是低秩的，可以分解为两个更小的矩阵：$$\\Delta W = A \\cdot B$$\n",
    "\n",
    "其中：\n",
    "-  $ A \\in \\mathbb{R}^{d \\times r} $\n",
    "-  $ B \\in \\mathbb{R}^{r \\times k} $\n",
    "-  $ r  是分解的秩（通常远小于d和k）$\n",
    "2. 冻结原始权重\n",
    "在训练过程中，原始权重$W$保持冻结状态，仅更新低秩矩阵$A$和$B$。这不仅减少了需要训练的参数，还保留了预训练模型的知识。\n",
    "3. 计算效率\n",
    "由于低秩矩阵的计算复杂度比完整权重矩阵低得多，LoRA显著提升了适配速度，同时降低了显存占用。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f61a84-0bd2-4941-ae13-9da317193629",
   "metadata": {},
   "source": [
    "## 3.1 Low-Rank Matrix\n",
    "在线性代数中，低秩矩阵是指一个矩阵的秩（rank）比它的行数或列数要小得多。简单来说，它是一种结构化的矩阵，表示其数据冗余性较高，很多信息可以用更少的自由度来表示。\n",
    "\n",
    "矩阵的秩（Rank）: 矩阵的秩是线性无关行或列的数量。\n",
    "\n",
    "对于一个 $ m \\times n $ 的矩阵  A ：\n",
    "- 全秩矩阵：如果 $ \\text{rank}(A) = \\min(m, n) $，矩阵信息完整，行或列是线性无关的。\n",
    "- \"低秩矩阵：如果 $ \\text{rank}(A) \\ll \\min(m, n) $，矩阵存在冗余，行或列是高度相关的。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4add762c-4fa3-4848-ba35-62b5b631ff20",
   "metadata": {},
   "source": [
    "低秩矩阵的实际例子\n",
    "\n",
    "1. 图像处理：\n",
    "在图像压缩中，图片的像素矩阵通常是近似低秩的，可以通过降维技术（如PCA）压缩数据。\n",
    "2. 推荐系统：\n",
    "用户-物品评分矩阵通常是稀疏的（大部分项为空），也可以近似为低秩矩阵，因为用户的评分行为通常可以归因于少数几个潜在特征（如偏好类型、价格敏感性等）。\n",
    "3. 自然语言处理：\n",
    "在语言模型中，大型权重矩阵可以近似为低秩形式，用来减少参数量并提升计算效率（例如LoRA方法）。\n",
    "低秩分解（Low-Rank Decomposition）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402cda96-24cd-45ff-a55c-d7317126d7dc",
   "metadata": {},
   "source": [
    "为了利用低秩矩阵的特性，我们可以将它分解成多个更小的矩阵：\n",
    "\n",
    "$$ A \\approx U \\cdot V^T $$\n",
    "\n",
    "- $A$ ：原始矩阵\n",
    "- $U$ ：表示特征的矩阵\n",
    "- $V^T$ ：表示组合权重的矩阵\n",
    "秩  $r$ ：通常 $ r \\ll \\min(m, n) $\n",
    "\n",
    "例如，通过奇异值分解（SVD）：\n",
    "\n",
    "$$ A = U \\Sigma V^T $$\n",
    "\n",
    "我们可以用较小的奇异值（低秩近似）来近似原始矩阵。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17d0f88-21aa-4fd1-b51d-0f6b44cf280b",
   "metadata": {},
   "source": [
    "\n",
    "# 4. Multimodal Model(多模态模型)\n",
    "\n",
    "多模态模型 (Multimodal Model) 是指能够同时处理和整合多种不同类型（模态）的数据的人工智能模型。模态是数据的类型或形式，例如：\n",
    "- 视觉模态：图像、视频\n",
    "- 语言模态：文本、语音\n",
    "- 感觉模态：触觉、气味\n",
    "- 其他模态：传感器数据、生物信号（如脑电波或心电图）\n",
    "\n",
    "通过整合多个模态的数据，模型可以更全面地理解和分析复杂的任务或场景。\n",
    "\n",
    "多模态模型的架构设计\n",
    "\n",
    "1.\t单模态特征提取：\n",
    "•\t每种模态使用专门的网络进行特征提取。例如：\n",
    "•\t图像：卷积神经网络（CNN）\n",
    "•\t文本：循环神经网络（RNN）或变换器（Transformer）\n",
    "2.\t模态间融合：\n",
    "•\t提取的特征通过以下方式进行融合：\n",
    "•\t早期融合：在特征提取之前就合并不同模态的原始数据。\n",
    "•\t中期融合：单独提取特征后，将这些特征在某一层合并。\n",
    "•\t后期融合：各模态单独完成部分任务，再将结果整合。\n",
    "3.\t联合优化：\n",
    "•\t模型在训练时，目标函数能够优化所有模态之间的联合表现。\n",
    "\n",
    "经典多模态模型示例\n",
    "\n",
    "1.\tCLIP (Contrastive Language–Image Pretraining)：\n",
    "•\t由 OpenAI 开发，可以同时理解图像和文字，通过对比学习捕捉二者的语义关联。\n",
    "•\t应用于图像检索和跨模态理解。\n",
    "2.\tDALL·E：\n",
    "•\t基于文本生成图像的模型，将文字和视觉模态紧密结合。\n",
    "3.\tVideoBERT：\n",
    "•\t将语言模型扩展到视频分析，通过视频帧和字幕数据联合建模。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a9a9b7-6f13-43c8-bd82-ee1493336318",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83d7bb8e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "001e124b-1847-43d8-b2f0-74ab2b9718ac",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
